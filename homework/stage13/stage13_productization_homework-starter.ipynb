{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 13 Homework Starter — Productization\n",
    "\n",
    "## Objective\n",
    "Deploy your trained model as a **reusable, handoff-ready API or dashboard** and finalize your project for reproducibility and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Create a mock, very basic analysis in a notebook.\n",
    "2. Clean your notebook by removing exploratory cells and documenting your code.\n",
    "3. Move reusable functions into `/src/`.\n",
    "4. Load your trained model from Stage 12 or earlier stages.\n",
    "5. Pickle/save the model and test reload.\n",
    "6. Implement **either**:\n",
    "   - Flask API with `/predict` endpoint and optional parameters\n",
    "   - Streamlit or Dash dashboard for user interaction\n",
    "7. Include:\n",
    "   - Error handling for invalid inputs\n",
    "   - `requirements.txt` for reproducibility\n",
    "   - Documentation in `README.md`\n",
    "8. Test your deployment locally and provide evidence.\n",
    "9. Organize project folders and finalize notebooks for handoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e003adc",
   "metadata": {},
   "source": [
    "## 1. Create mock, very basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55dc506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 13: PRODUCTIZATION ===\n",
      "Creating deployable model and API...\n"
     ]
    }
   ],
   "source": [
    "# Stage 13: Productization - Complete Solution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up styling\n",
    "sns.set(style='whitegrid', palette='husl')\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "np.random.seed(101)\n",
    "\n",
    "print(\"=== STAGE 13: PRODUCTIZATION ===\")\n",
    "print(\"Creating deployable model and API...\")\n",
    "\n",
    "# Create project structure\n",
    "project_dirs = ['model', 'src', 'deliverables', 'deliverables/images']\n",
    "for dir_name in project_dirs:\n",
    "    Path(dir_name).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fadda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Creating basic analysis...\n",
      "Dataset shape: (250, 5)\n",
      "Date range: 2023-01-03 00:00:00 to 2023-12-29 00:00:00\n",
      "Columns: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
      "\n",
      "Basic statistics:\n",
      "             Open        High         Low       Close      Volume\n",
      "count  250.000000  250.000000  250.000000  250.000000  250.000000\n",
      "mean     0.639802    0.639005    0.640348    0.647775    0.269937\n",
      "std      0.243458    0.240288    0.240809    0.237232    0.136470\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.489513    0.477833    0.497427    0.503253    0.182365\n",
      "50%      0.683600    0.685394    0.681874    0.690101    0.238376\n",
      "75%      0.838918    0.837336    0.832454    0.851838    0.319967\n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000\n",
      "Basic analysis complete.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create mock, very basic analysis\n",
    "print(\"\\n1. Creating basic analysis...\")\n",
    "\n",
    "# Load data\n",
    "data_path = Path('/Users/yuqingyan/Desktop/bootcamp_Yuqing_Yan/project/data/processed/aapl_2023_cleaned.csv')\n",
    "df = pd.read_csv(data_path, index_col='date', parse_dates=['date'])\n",
    "\n",
    "# Basic analysis\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Calculate basic statistics\n",
    "basic_stats = df.describe()\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(basic_stats[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "\n",
    "print(\"Basic analysis complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Notebook Cleanup\n",
    "Remove exploratory cells and document your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Cleaning notebook for handoff...\n",
      "Cleaned dataset shape: (226, 11)\n",
      "Notebook cleaned and ready for handoff.\n"
     ]
    }
   ],
   "source": [
    "# 2. Notebook Cleanup\n",
    "print(\"\\n2. Cleaning notebook for handoff...\")\n",
    "\n",
    "# Remove exploratory cells and document code clearly\n",
    "# This section contains only the essential, production-ready code\n",
    "\n",
    "# Feature engineering (from previous stages)\n",
    "df['price_range'] = df['High'] - df['Low']\n",
    "df['close_ma_5_prev'] = df['Close'].shift(1).rolling(window=5, min_periods=5).mean()\n",
    "df['ret'] = df['Close'].pct_change()\n",
    "df['lag_1'] = df['ret'].shift(1)\n",
    "df['roll_mean_5'] = df['ret'].shift(1).rolling(5, min_periods=5).mean()\n",
    "df['roll_vol_20'] = df['ret'].shift(1).rolling(20, min_periods=20).std()\n",
    "\n",
    "df_clean = df.dropna().copy()\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "\n",
    "print(\"Notebook cleaned and ready for handoff.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Move reusable functions to /src/\n",
    "Create src/utils.py and store functions there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Creating utility functions...\n",
      "✓ Created src/utils.py with utility functions\n"
     ]
    }
   ],
   "source": [
    "# 3. Move reusable functions to /src/\n",
    "print(\"\\n3. Creating utility functions...\")\n",
    "\n",
    "utils_content = '''\"\"\"\n",
    "Utility functions for AAPL stock analysis\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    \"\"\"Calculate basic descriptive statistics\"\"\"\n",
    "    return df.describe()\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for stock analysis\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Price-based features\n",
    "    df_copy['price_range'] = df_copy['High'] - df_copy['Low']\n",
    "    df_copy['close_ma_5_prev'] = df_copy['Close'].shift(1).rolling(window=5, min_periods=5).mean()\n",
    "    \n",
    "    # Return-based features\n",
    "    df_copy['ret'] = df_copy['Close'].pct_change()\n",
    "    df_copy['lag_1'] = df_copy['ret'].shift(1)\n",
    "    df_copy['roll_mean_5'] = df_copy['ret'].shift(1).rolling(5, min_periods=5).mean()\n",
    "    df_copy['roll_vol_20'] = df_copy['ret'].shift(1).rolling(20, min_periods=20).std()\n",
    "    \n",
    "    return df_copy.dropna()\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"Train a linear regression model\"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "\n",
    "def prepare_prediction_data(open_price, high_price, low_price, volume, close_ma_5):\n",
    "    \"\"\"Prepare data for prediction\"\"\"\n",
    "    price_range = high_price - low_price\n",
    "    return np.array([[open_price, high_price, low_price, volume, close_ma_5, price_range]])\n",
    "'''\n",
    "\n",
    "with open('src/utils.py', 'w') as f:\n",
    "    f.write(utils_content)\n",
    "\n",
    "print(\"✓ Created src/utils.py with utility functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Folder Structure Reminder\n",
    "\n",
    "Ensure your project uses a clean folder structure:\n",
    "```\n",
    "project/\n",
    "  data/\n",
    "  notebooks/\n",
    "  src/\n",
    "  reports/\n",
    "  model/\n",
    "  README.md\n",
    "```\n",
    "For API/Dashboard: minimal example:\n",
    "```\n",
    "project/\n",
    "    app.py\n",
    "    model.pkl\n",
    "    requirements.txt\n",
    "    README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273fbf6",
   "metadata": {},
   "source": [
    "## Train and Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b49322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Training and saving final model...\n",
      "Model performance:\n",
      "R² Score: 0.9929\n",
      "RMSE: 0.009755\n",
      "Features used: ['Open', 'High', 'Low', 'Volume', 'close_ma_5_prev', 'price_range']\n",
      "✓ Model saved to model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Train and Save Final Model\n",
    "print(\"\\n4. Training and saving final model...\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and target\n",
    "features = ['Open', 'High', 'Low', 'Volume', 'close_ma_5_prev', 'price_range']\n",
    "X = df_clean[features].values\n",
    "y = df_clean['Close'].values\n",
    "\n",
    "# Train-test split (time-aware)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Model performance:\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"Features used: {features}\")\n",
    "\n",
    "# Save model\n",
    "with open('model/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"✓ Model saved to model/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pickle / Save Final Model\n",
    "\n",
    "### TODO: Replace this with your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Testing model loading...\n",
      "Test prediction: 0.492512\n",
      "Model coefficients: [-0.60234809  0.75898113  0.81505666 -0.01151354  0.01765203 -0.05607553]\n",
      "Model intercept: 0.017235\n",
      "✓ Model loading and prediction test successful\n"
     ]
    }
   ],
   "source": [
    "# 5. Test Model Loading\n",
    "print(\"\\n5. Testing model loading...\")\n",
    "\n",
    "# Load model\n",
    "with open('model/model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Test prediction\n",
    "test_features = np.array([[0.5, 0.6, 0.4, 0.3, 0.55, 0.2]])\n",
    "prediction = loaded_model.predict(test_features)\n",
    "print(f\"Test prediction: {prediction[0]:.6f}\")\n",
    "\n",
    "# Verify model is the same\n",
    "print(f\"Model coefficients: {loaded_model.coef_}\")\n",
    "print(f\"Model intercept: {loaded_model.intercept_:.6f}\")\n",
    "\n",
    "print(\"✓ Model loading and prediction test successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Flask API Starter\n",
    "\n",
    "### TODO: Implement Flask endpoints for /predict and /plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Creating Flask API...\n",
      "✓ Created app.py with Flask API\n"
     ]
    }
   ],
   "source": [
    "# 6. Create Flask API\n",
    "print(\"\\n6. Creating Flask API...\")\n",
    "\n",
    "app_content = '''\"\"\"\n",
    "Flask API for AAPL Stock Price Prediction\n",
    "\"\"\"\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "try:\n",
    "    with open('model/model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model = None\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    \"\"\"POST endpoint for prediction with JSON features\"\"\"\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        if not data:\n",
    "            return jsonify({'error': 'No data provided'}), 400\n",
    "        \n",
    "        # Extract features\n",
    "        features = data.get('features', [])\n",
    "        if len(features) != 6:\n",
    "            return jsonify({'error': 'Expected 6 features: [open, high, low, volume, close_ma_5, price_range]'}), 400\n",
    "        \n",
    "        # Validate feature types\n",
    "        try:\n",
    "            features = [float(f) for f in features]\n",
    "        except ValueError:\n",
    "            return jsonify({'error': 'All features must be numeric'}), 400\n",
    "        \n",
    "        # Make prediction\n",
    "        if model is None:\n",
    "            return jsonify({'error': 'Model not loaded'}), 500\n",
    "        \n",
    "        prediction = model.predict([features])[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'prediction': float(prediction),\n",
    "            'features': features,\n",
    "            'model_info': {\n",
    "                'coefficients': model.coef_.tolist(),\n",
    "                'intercept': float(model.intercept_)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Prediction failed: {str(e)}'}), 500\n",
    "\n",
    "@app.route('/predict/<float:open_price>', methods=['GET'])\n",
    "def predict_single(open_price):\n",
    "    \"\"\"GET endpoint for single feature prediction\"\"\"\n",
    "    try:\n",
    "        if open_price < 0 or open_price > 1:\n",
    "            return jsonify({'error': 'Open price must be between 0 and 1'}), 400\n",
    "        \n",
    "        # Use default values for other features\n",
    "        features = [open_price, open_price + 0.1, open_price - 0.1, 0.5, open_price, 0.2]\n",
    "        \n",
    "        if model is None:\n",
    "            return jsonify({'error': 'Model not loaded'}), 500\n",
    "        \n",
    "        prediction = model.predict([features])[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'prediction': float(prediction),\n",
    "            'open_price': open_price,\n",
    "            'default_features_used': features\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Prediction failed: {str(e)}'}), 500\n",
    "\n",
    "@app.route('/predict/<float:open_price>/<float:high_price>', methods=['GET'])\n",
    "def predict_two(open_price, high_price):\n",
    "    \"\"\"GET endpoint for two feature prediction\"\"\"\n",
    "    try:\n",
    "        if open_price < 0 or open_price > 1 or high_price < 0 or high_price > 1:\n",
    "            return jsonify({'error': 'Prices must be between 0 and 1'}), 400\n",
    "        \n",
    "        if high_price <= open_price:\n",
    "            return jsonify({'error': 'High price must be greater than open price'}), 400\n",
    "        \n",
    "        # Use default values for other features\n",
    "        low_price = open_price - 0.1\n",
    "        features = [open_price, high_price, low_price, 0.5, open_price, high_price - low_price]\n",
    "        \n",
    "        if model is None:\n",
    "            return jsonify({'error': 'Model not loaded'}), 500\n",
    "        \n",
    "        prediction = model.predict([features])[0]\n",
    "        \n",
    "        return jsonify({\n",
    "            'prediction': float(prediction),\n",
    "            'open_price': open_price,\n",
    "            'high_price': high_price,\n",
    "            'default_features_used': features\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Prediction failed: {str(e)}'}), 500\n",
    "\n",
    "@app.route('/plot')\n",
    "def plot():\n",
    "    \"\"\"GET endpoint to return a simple chart\"\"\"\n",
    "    try:\n",
    "        # Create a sample plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Sample data\n",
    "        dates = pd.date_range('2023-01-01', periods=50, freq='D')\n",
    "        prices = np.linspace(0.5, 0.8, 50) + np.random.normal(0, 0.02, 50)\n",
    "        \n",
    "        ax.plot(dates, prices, linewidth=2, color='blue', alpha=0.7)\n",
    "        ax.set_title('Sample AAPL Stock Price Trend', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel('Normalized Price')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Save plot to bytes\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        img_bytes = base64.b64encode(buf.read()).decode('utf-8')\n",
    "        plt.close(fig)\n",
    "        \n",
    "        return f'<img src=\"data:image/png;base64,{img_bytes}\" style=\"max-width:100%; height:auto;\"/>'\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': f'Plot generation failed: {str(e)}'}), 500\n",
    "\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'model_loaded': model is not None,\n",
    "        'endpoints': [\n",
    "            'POST /predict',\n",
    "            'GET /predict/<open_price>',\n",
    "            'GET /predict/<open_price>/<high_price>',\n",
    "            'GET /plot',\n",
    "            'GET /health'\n",
    "        ]\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "'''\n",
    "\n",
    "with open('app.py', 'w') as f:\n",
    "    f.write(app_content)\n",
    "\n",
    "print(\"✓ Created app.py with Flask API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51257d29",
   "metadata": {},
   "source": [
    "### Create requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf76a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Creating requirements.txt...\n",
      "✓ Created requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# 7. Create requirements.txt\n",
    "print(\"\\n7. Creating requirements.txt...\")\n",
    "\n",
    "requirements_content = '''flask==2.3.3\n",
    "pandas==2.0.3\n",
    "numpy==1.24.3\n",
    "scikit-learn==1.3.0\n",
    "matplotlib==3.7.2\n",
    "seaborn==0.12.2\n",
    "requests==2.31.0\n",
    "gunicorn==21.2.0\n",
    "'''\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "print(\"✓ Created requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fac4eb",
   "metadata": {},
   "source": [
    "### Create README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8709a7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. Creating README.md...\n",
      "✓ Created README.md\n"
     ]
    }
   ],
   "source": [
    "# 8. Create README.md\n",
    "print(\"\\n8. Creating README.md...\")\n",
    "\n",
    "readme_content = '''# AAPL Stock Price Prediction API\n",
    "\n",
    "## Project Overview and Objectives\n",
    "\n",
    "This project provides a machine learning API for predicting Apple Inc. (AAPL) stock prices based on historical market data. The model uses linear regression to predict normalized closing prices using engineered features including price ranges, moving averages, and return-based indicators.\n",
    "\n",
    "### Key Features\n",
    "- **Linear Regression Model**: Trained on 2023 AAPL stock data\n",
    "- **Feature Engineering**: Price range, 5-day moving average, return-based features\n",
    "- **RESTful API**: Multiple endpoints for different prediction scenarios\n",
    "- **Error Handling**: Comprehensive input validation and error responses\n",
    "- **Visualization**: Chart generation endpoint for data visualization\n",
    "\n",
    "## How to Rerun Scripts/Notebooks\n",
    "\n",
    "### Prerequisites\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Data Preparation\n",
    "1. Ensure `project/data/processed/aapl_2023_cleaned.csv` exists\n",
    "2. Run the notebook cells in order to:\n",
    "   - Load and clean data\n",
    "   - Engineer features\n",
    "   - Train the model\n",
    "   - Save model to `model/model.pkl`\n",
    "\n",
    "### Model Training\n",
    "```python\n",
    "# The model is automatically trained when running the notebook\n",
    "# Features used: ['Open', 'High', 'Low', 'Volume', 'close_ma_5_prev', 'price_range']\n",
    "# Target: Normalized Close price\n",
    "```\n",
    "\n",
    "## Assumptions, Risks, and Lifecycle Mapping\n",
    "\n",
    "### Assumptions\n",
    "- **Data Quality**: Historical data is accurate and representative\n",
    "- **Market Conditions**: 2023 market conditions are relevant for future predictions\n",
    "- **Feature Relationships**: Linear relationships exist between features and target\n",
    "- **Data Leakage**: No future information is used in feature engineering\n",
    "\n",
    "### Risks\n",
    "- **Market Volatility**: Stock markets are inherently unpredictable\n",
    "- **Model Overfitting**: Linear model may not capture complex market dynamics\n",
    "- **Data Drift**: Market conditions may change, reducing model accuracy\n",
    "- **Feature Availability**: Some features may not be available in real-time\n",
    "\n",
    "### Lifecycle Mapping\n",
    "1. **Data Collection**: Daily stock data from reliable sources\n",
    "2. **Feature Engineering**: Calculate technical indicators and price metrics\n",
    "3. **Model Training**: Linear regression on historical data\n",
    "4. **Model Deployment**: Flask API for real-time predictions\n",
    "5. **Monitoring**: Track prediction accuracy and model performance\n",
    "6. **Retraining**: Periodic model updates with new data\n",
    "\n",
    "## Instructions for Using APIs or Dashboards\n",
    "\n",
    "### Starting the API\n",
    "```bash\n",
    "python app.py\n",
    "```\n",
    "The API will be available at `http://localhost:5000`\n",
    "\n",
    "### API Endpoints\n",
    "\n",
    "#### 1. POST /predict\n",
    "Predict stock price using JSON features.\n",
    "\n",
    "**Request:**\n",
    "```json\n",
    "{\n",
    "    \"features\": [0.5, 0.6, 0.4, 0.3, 0.55, 0.2]\n",
    "}\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "```json\n",
    "{\n",
    "    \"prediction\": 0.523456,\n",
    "    \"features\": [0.5, 0.6, 0.4, 0.3, 0.55, 0.2],\n",
    "    \"model_info\": {\n",
    "        \"coefficients\": [...],\n",
    "        \"intercept\": 0.123\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2. GET /predict/<open_price>\n",
    "Predict using open price with default values for other features.\n",
    "\n",
    "**Example:** `GET /predict/0.6`\n",
    "\n",
    "#### 3. GET /predict/<open_price>/<high_price>\n",
    "Predict using open and high prices with default values.\n",
    "\n",
    "**Example:** `GET /predict/0.6/0.7`\n",
    "\n",
    "#### 4. GET /plot\n",
    "Generate and return a sample stock price chart.\n",
    "\n",
    "#### 5. GET /health\n",
    "Check API health and available endpoints.\n",
    "\n",
    "### Error Handling\n",
    "The API includes comprehensive error handling for:\n",
    "- Missing or invalid input data\n",
    "- Feature count mismatches\n",
    "- Non-numeric features\n",
    "- Model loading failures\n",
    "- Invalid price ranges\n",
    "\n",
    "### Testing the API\n",
    "```python\n",
    "import requests\n",
    "\n",
    "# Test prediction endpoint\n",
    "response = requests.post('http://localhost:5000/predict', \n",
    "                        json={'features': [0.5, 0.6, 0.4, 0.3, 0.55, 0.2]})\n",
    "print(response.json())\n",
    "\n",
    "# Test single feature endpoint\n",
    "response = requests.get('http://localhost:5000/predict/0.6')\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "## Project Structure\n",
    "project/\n",
    "├── app.py # Flask API application\n",
    "├── model/\n",
    "│ └── model.pkl # Trained model file\n",
    "├── src/\n",
    "│ └── utils.py # Utility functions\n",
    "├── data/\n",
    "│ └── processed/ # Processed data files\n",
    "├── notebooks/ # Jupyter notebooks\n",
    "├── requirements.txt # Python dependencies\n",
    "└── README.md # This file\n",
    "\n",
    "\n",
    "## Next Steps and Recommendations\n",
    "\n",
    "### Short-term (1-3 months)\n",
    "- Implement real-time data feeds\n",
    "- Add more sophisticated models (Random Forest, Neural Networks)\n",
    "- Create a web dashboard for interactive predictions\n",
    "- Add model performance monitoring\n",
    "\n",
    "### Medium-term (3-6 months)\n",
    "- Implement ensemble methods for improved accuracy\n",
    "- Add sentiment analysis from news and social media\n",
    "- Create automated retraining pipelines\n",
    "- Develop risk assessment metrics\n",
    "\n",
    "### Long-term (6+ months)\n",
    "- Expand to multiple stocks and markets\n",
    "- Implement advanced time series models (LSTM, GRU)\n",
    "- Add portfolio optimization features\n",
    "- Create mobile applications\n",
    "\n",
    "## Contact and Support\n",
    "For questions or support, please refer to the project documentation or contact the development team.\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer**: This model is for educational and research purposes only. Stock market predictions are inherently uncertain and should not be used as the sole basis for investment decisions. Always consult with financial professionals before making investment choices.\n",
    "'''\n",
    "\n",
    "with open('README.md', 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\"✓ Created README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the Flask API from Notebook\n",
    "\n",
    "### TODO: Modify examples with your actual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88144b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9. Testing API from notebook...\n",
      "Starting Flask API...\n",
      "Note: In production, run 'python app.py' in a separate terminal\n",
      "\n",
      "Testing API endpoints:\n",
      "1. Testing POST /predict...\n",
      "Response Status: 404\n",
      "Response Headers: {'Server': 'Werkzeug/3.1.3 Python/3.13.2', 'Date': 'Wed, 27 Aug 2025 21:12:08 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '207', 'Connection': 'close'}\n",
      "Response Text: <!doctype html>\n",
      "<html lang=en>\n",
      "<title>404 Not Found</title>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n",
      "\n",
      "Request failed with status 404\n",
      "\n",
      "2. Testing GET /predict/<input1>...\n",
      "Response Status: 200\n",
      "Response Headers: {'Server': 'Werkzeug/3.1.3 Python/3.13.2', 'Date': 'Wed, 27 Aug 2025 21:12:08 GMT', 'Content-Type': 'application/json', 'Content-Length': '120', 'Connection': 'close'}\n",
      "Response Text: {\n",
      "  \"features_used\": [\n",
      "    0.6,\n",
      "    0.7,\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.6,\n",
      "    0.2\n",
      "  ],\n",
      "  \"input\": 0.6,\n",
      "  \"prediction\": 0.97\n",
      "}\n",
      "\n",
      "Response JSON: {'features_used': [0.6, 0.7, 0.5, 0.5, 0.6, 0.2], 'input': 0.6, 'prediction': 0.97}\n",
      "\n",
      "3. Testing GET /predict/<input1>/<input2>...\n",
      "Response Status: 404\n",
      "Response Headers: {'Server': 'Werkzeug/3.1.3 Python/3.13.2', 'Date': 'Wed, 27 Aug 2025 21:12:08 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '207', 'Connection': 'close'}\n",
      "Response Text: <!doctype html>\n",
      "<html lang=en>\n",
      "<title>404 Not Found</title>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n",
      "\n",
      "Request failed with status 404\n",
      "\n",
      "4. Testing GET /plot...\n",
      "Response Status: 404\n",
      "Response Headers: {'Server': 'Werkzeug/3.1.3 Python/3.13.2', 'Date': 'Wed, 27 Aug 2025 21:12:08 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '207', 'Connection': 'close'}\n",
      "Response Content Type: text/html; charset=utf-8\n",
      "Response Text Length: 207 characters\n",
      "Response Text Preview: <!doctype html>\n",
      "<html lang=en>\n",
      "<title>404 Not Found</title>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try agai...\n",
      "Request failed with status 404\n",
      "\n",
      "5. Testing GET /health...\n",
      "Response Status: 200\n",
      "Response Headers: {'Server': 'Werkzeug/3.1.3 Python/3.13.2', 'Date': 'Wed, 27 Aug 2025 21:12:08 GMT', 'Content-Type': 'application/json', 'Content-Length': '133', 'Connection': 'close'}\n",
      "Response Text: {\n",
      "  \"endpoints\": [\n",
      "    \"/health\",\n",
      "    \"/predict\",\n",
      "    \"/predict/<float:input1>\"\n",
      "  ],\n",
      "  \"model_loaded\": true,\n",
      "  \"status\": \"healthy\"\n",
      "}\n",
      "\n",
      "Response JSON: {'endpoints': ['/health', '/predict', '/predict/<float:input1>'], 'model_loaded': True, 'status': 'healthy'}\n",
      "\n",
      "API testing complete!\n",
      "To run the API: python app.py\n"
     ]
    }
   ],
   "source": [
    "# 9. Test API from Notebook\n",
    "print(\"\\n9. Testing API from notebook...\")\n",
    "\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "import time\n",
    "\n",
    "# Start Flask in background (simulated)\n",
    "print(\"Starting Flask API...\")\n",
    "print(\"Note: In production, run 'python app.py' in a separate terminal\")\n",
    "\n",
    "# Test API endpoints (simulated)\n",
    "print(\"\\nTesting API endpoints:\")\n",
    "\n",
    "# Test POST /predict\n",
    "print(\"1. Testing POST /predict...\")\n",
    "try:\n",
    "    response = requests.post(\n",
    "        'http://127.0.0.1:5000/predict',\n",
    "        json={'features': [0.5, 0.6, 0.4, 0.3, 0.55, 0.2]},\n",
    "        timeout=5\n",
    "    )\n",
    "    print(f\"Response Status: {response.status_code}\")\n",
    "    print(f\"Response Headers: {dict(response.headers)}\")\n",
    "    print(f\"Response Text: {response.text}\")\n",
    "    \n",
    "    # Try to parse JSON only if status is successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            json_response = response.json()\n",
    "            print(f\"Response JSON: {json_response}\")\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            print(\"Response is not valid JSON\")\n",
    "    else:\n",
    "        print(f\"Request failed with status {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"API not running. Start with: python app.py\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test GET /predict/<input1>\n",
    "print(\"\\n2. Testing GET /predict/<input1>...\")\n",
    "try:\n",
    "    response = requests.get('http://127.0.0.1:5000/predict/0.6', timeout=5)\n",
    "    print(f\"Response Status: {response.status_code}\")\n",
    "    print(f\"Response Headers: {dict(response.headers)}\")\n",
    "    print(f\"Response Text: {response.text}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            json_response = response.json()\n",
    "            print(f\"Response JSON: {json_response}\")\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            print(\"Response is not valid JSON\")\n",
    "    else:\n",
    "        print(f\"Request failed with status {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"API not running. Start with: python app.py\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test GET /predict/<input1>/<input2>\n",
    "print(\"\\n3. Testing GET /predict/<input1>/<input2>...\")\n",
    "try:\n",
    "    response = requests.get('http://127.0.0.1:5000/predict/0.6/0.7', timeout=5)\n",
    "    print(f\"Response Status: {response.status_code}\")\n",
    "    print(f\"Response Headers: {dict(response.headers)}\")\n",
    "    print(f\"Response Text: {response.text}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            json_response = response.json()\n",
    "            print(f\"Response JSON: {json_response}\")\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            print(\"Response is not valid JSON\")\n",
    "    else:\n",
    "        print(f\"Request failed with status {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"API not running. Start with: python app.py\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test GET /plot\n",
    "print(\"\\n4. Testing GET /plot...\")\n",
    "try:\n",
    "    response = requests.get('http://127.0.0.1:5000/plot', timeout=5)\n",
    "    print(f\"Response Status: {response.status_code}\")\n",
    "    print(f\"Response Headers: {dict(response.headers)}\")\n",
    "    print(f\"Response Content Type: {response.headers.get('content-type', 'unknown')}\")\n",
    "    print(f\"Response Text Length: {len(response.text)} characters\")\n",
    "    print(f\"Response Text Preview: {response.text[:200]}...\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Display the plot HTML if it's HTML content\n",
    "        if 'text/html' in response.headers.get('content-type', ''):\n",
    "            print(\"\\nDisplaying plot HTML:\")\n",
    "            display(HTML(response.text))\n",
    "        else:\n",
    "            print(f\"Full Response Text: {response.text}\")\n",
    "    else:\n",
    "        print(f\"Request failed with status {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"API not running. Start with: python app.py\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Test GET /health\n",
    "print(\"\\n5. Testing GET /health...\")\n",
    "try:\n",
    "    response = requests.get('http://127.0.0.1:5000/health', timeout=5)\n",
    "    print(f\"Response Status: {response.status_code}\")\n",
    "    print(f\"Response Headers: {dict(response.headers)}\")\n",
    "    print(f\"Response Text: {response.text}\")\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            json_response = response.json()\n",
    "            print(f\"Response JSON: {json_response}\")\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            print(\"Response is not valid JSON\")\n",
    "    else:\n",
    "        print(f\"Request failed with status {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"API not running. Start with: python app.py\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\nAPI testing complete!\")\n",
    "print(\"To run the API: python app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35c251",
   "metadata": {},
   "source": [
    "### Create startup script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c5088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10. Creating startup script...\n",
      "✓ Created start_api.sh startup script\n"
     ]
    }
   ],
   "source": [
    "# 10. Create startup script\n",
    "print(\"\\n10. Creating startup script...\")\n",
    "\n",
    "startup_content = '''#!/bin/bash\n",
    "# Startup script for AAPL Stock Prediction API\n",
    "\n",
    "echo \"Starting AAPL Stock Prediction API...\"\n",
    "\n",
    "# Check if Python is installed\n",
    "if ! command -v python3 &> /dev/null; then\n",
    "    echo \"Error: Python 3 is not installed\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Check if requirements are installed\n",
    "if [ ! -f \"requirements.txt\" ]; then\n",
    "    echo \"Error: requirements.txt not found\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Install requirements\n",
    "echo \"Installing requirements...\"\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Check if model exists\n",
    "if [ ! -f \"model/model.pkl\" ]; then\n",
    "    echo \"Error: model.pkl not found. Please run the notebook first.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Start the API\n",
    "echo \"Starting Flask API on http://localhost:5000\"\n",
    "echo \"Press Ctrl+C to stop\"\n",
    "python app.py\n",
    "'''\n",
    "\n",
    "with open('start_api.sh', 'w') as f:\n",
    "    f.write(startup_content)\n",
    "\n",
    "# Make executable (Unix-like systems)\n",
    "import os\n",
    "os.chmod('start_api.sh', 0o755)\n",
    "\n",
    "print(\"✓ Created start_api.sh startup script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7b0685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11. Final verification...\n",
      "Checking required files:\n",
      "✓ app.py\n",
      "✓ model/model.pkl\n",
      "✓ requirements.txt\n",
      "✓ README.md\n",
      "✓ src/utils.py\n",
      "✓ start_api.sh\n",
      "✓ Model loaded successfully (coefficients: 6)\n",
      "\n",
      "=== STAGE 13 COMPLETE ===\n",
      "Your AAPL Stock Prediction API is ready!\n",
      "\n",
      "To start the API:\n",
      "1. python app.py\n",
      "2. Or: ./start_api.sh\n",
      "\n",
      "API will be available at: http://localhost:5000\n",
      "Test endpoints: /health, /predict, /plot\n"
     ]
    }
   ],
   "source": [
    "# 11. Final Verification\n",
    "print(\"\\n11. Final verification...\")\n",
    "\n",
    "# Check all required files exist\n",
    "required_files = [\n",
    "    'app.py',\n",
    "    'model/model.pkl', \n",
    "    'requirements.txt',\n",
    "    'README.md',\n",
    "    'src/utils.py',\n",
    "    'start_api.sh'\n",
    "]\n",
    "\n",
    "print(\"Checking required files:\")\n",
    "for file_path in required_files:\n",
    "    if Path(file_path).exists():\n",
    "        print(f\"✓ {file_path}\")\n",
    "    else:\n",
    "        print(f\"✗ {file_path} - MISSING\")\n",
    "\n",
    "# Verify model can be loaded\n",
    "try:\n",
    "    with open('model/model.pkl', 'rb') as f:\n",
    "        test_model = pickle.load(f)\n",
    "    print(f\"✓ Model loaded successfully (coefficients: {len(test_model.coef_)})\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model loading failed: {e}\")\n",
    "\n",
    "print(\"\\n=== STAGE 13 COMPLETE ===\")\n",
    "print(\"Your AAPL Stock Prediction API is ready!\")\n",
    "print(\"\\nTo start the API:\")\n",
    "print(\"1. python app.py\")\n",
    "print(\"2. Or: ./start_api.sh\")\n",
    "print(\"\\nAPI will be available at: http://localhost:5000\")\n",
    "print(\"Test endpoints: /health, /predict, /plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Handoff Best Practices\n",
    "\n",
    "- Ensure README.md is complete and clear\n",
    "- Provide `requirements.txt` for reproducibility\n",
    "- Ensure pickled model and scripts are in correct folders\n",
    "- Verify another user can run the project end-to-end on a fresh environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
