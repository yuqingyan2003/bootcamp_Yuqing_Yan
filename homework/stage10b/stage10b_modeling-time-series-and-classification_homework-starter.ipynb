{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter â€” Stage 10b: Time Series & Classification\n",
    "Fill in the TODOs. Use your own dataset or adapt the synthetic generator below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "np.random.seed(7); sns.set(); plt.rcParams['figure.figsize']=(9,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Use Your Own Data (Recommended)\n",
    "Load your data here (ensure a DateTime index for time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load your data\n",
    "# df = pd.read_csv('path/to.csv', parse_dates=['Date'], index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B: Synthetic Generator (Use if you don't have data ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic series with regimes & jumps\n",
    "n=500\n",
    "dates=pd.bdate_range('2021-01-01', periods=n)\n",
    "mu = np.where(np.arange(n)<n//2, 0.0003, -0.0001)\n",
    "sigma = np.where(np.arange(n)<n//2, 0.01, 0.015)\n",
    "eps = np.random.normal(mu, sigma)\n",
    "jumps = np.zeros(n); jump_days = np.random.choice(np.arange(20,n-20), size=5, replace=False)\n",
    "jumps[jump_days] = np.random.normal(0,0.05,size=len(jump_days))\n",
    "rets = eps + jumps\n",
    "price = 100*np.exp(np.cumsum(rets))\n",
    "df = pd.DataFrame({'price':price}, index=dates)\n",
    "df['ret'] = df['price'].pct_change().fillna(0.0)\n",
    "df['log_ret'] = np.log1p(df['ret'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create at least two features\n",
    "df['lag_1'] = df['ret'].shift(1)\n",
    "df['roll_mean_5'] = df['ret'].rolling(5).mean().shift(1)\n",
    "# Add your own:\n",
    "# df['roll_vol_20'] = df['ret'].rolling(20).std().shift(1)\n",
    "df['y_next_ret'] = df['ret'].shift(-1)\n",
    "df['y_up'] = (df['y_next_ret']>0).astype(int)\n",
    "df_feat = df.dropna().copy()\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-aware split\n",
    "cut=int(len(df_feat)*0.8)\n",
    "train, test = df_feat.iloc[:cut], df_feat.iloc[cut:]\n",
    "features=['lag_1','roll_mean_5']  # extend as you add features\n",
    "X_tr, X_te = train[features], test[features]\n",
    "y_tr_reg, y_te_reg = train['y_next_ret'], test['y_next_ret']\n",
    "y_tr_clf, y_te_clf = train['y_up'], test['y_up']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline + Model (Choose one track below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 1: Forecasting returns\n",
    "reg = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "reg.fit(X_tr, y_tr_reg)\n",
    "pred = reg.predict(X_te)\n",
    "rmse = mean_squared_error(y_te_reg, pred, squared=False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 2: Classification (up/down)\n",
    "clf = Pipeline([('scaler', StandardScaler()), ('logit', LogisticRegression(max_iter=1000))])\n",
    "clf.fit(X_tr, y_tr_clf)\n",
    "predc = clf.predict(X_te)\n",
    "print(classification_report(y_te_clf, predc))\n",
    "cm = confusion_matrix(y_te_clf, predc)\n",
    "sns.heatmap(cm, annot=True, fmt='d'); plt.title('Confusion Matrix'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation (Markdown)\n",
    "- What worked?\n",
    "- Where might assumptions fail?\n",
    "- How would you extend features or model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Notebook\n",
    "Remember to save as `notebooks/modeling_<team>.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
