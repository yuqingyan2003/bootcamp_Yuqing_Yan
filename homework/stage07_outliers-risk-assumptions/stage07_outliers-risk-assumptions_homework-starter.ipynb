{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3848df1c",
      "metadata": {},
      "source": [
        "# Setup: Generate Sample Dataset\n",
        "\n",
        "This cell creates the required folder structure (`data/raw/` and `data/processed/`) relative to the notebook, and generates the sample CSV dataset with missing values. \n",
        "This ensures the dataset is ready for cleaning functions and saves it to `data/raw/outliers_homework.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c50b376",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define folder paths relative to this notebook\n",
        "raw_dir = '../data/raw'\n",
        "processed_dir = '../data/processed'\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(raw_dir, exist_ok=True)\n",
        "os.makedirs(processed_dir, exist_ok=True)\n",
        "\n",
        "# Generate business day dates\n",
        "dates = pd.date_range(start=\"2022-01-03\", end=\"2022-06-10\", freq=\"B\")\n",
        "\n",
        "# Fixed random seed for reproducibility\n",
        "np.random.seed(17)\n",
        "\n",
        "# Column 1: daily_return ~ N(0, 0.01)\n",
        "returns = np.random.normal(0, 0.01, size=len(dates))\n",
        "mask_pre_may = dates < \"2022-05-01\"\n",
        "returns[mask_pre_may] -= 0.0015  \n",
        "\n",
        "# Inject \"shock\" values\n",
        "shock_values = {\n",
        "    \"2022-05-02\": 0.1748425237194541,\n",
        "    \"2022-05-03\": -0.16825801732486943,\n",
        "    \"2022-05-06\": -0.19667220757153227,\n",
        "    \"2022-05-09\": 0.21240223590614747,\n",
        "    \"2022-05-12\": -0.178729287231294\n",
        "}\n",
        "for d, v in shock_values.items():\n",
        "    idx = np.where(dates == pd.to_datetime(d))[0][0]\n",
        "    returns[idx] = v\n",
        "\n",
        "# Column 2: daily_return_2, correlated with daily_return + small noise\n",
        "daily_return_2 = returns * 0.6 + np.random.normal(0, 0.005, size=len(dates))\n",
        "\n",
        "# Create DataFrame with two numeric columns\n",
        "df = pd.DataFrame({\n",
        "    \"date\": dates,\n",
        "    \"daily_return\": returns,\n",
        "    \"daily_return_2\": daily_return_2\n",
        "})\n",
        "\n",
        "# Save to CSV in raw data folder\n",
        "csv_path = os.path.join(raw_dir, 'outliers_homework.csv')\n",
        "if not os.path.exists(csv_path):\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f'Synthetic dataset with two columns created and saved to {csv_path}')\n",
        "else:\n",
        "    print(f'File already exists at {csv_path}. Skipping CSV creation to avoid overwrite.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 7 Homework — Outliers + Risk Assumptions\n",
        "In this assignment you will implement outlier detection/handling and run a simple sensitivity analysis.\n",
        "\n",
        "**Chain:** In the lecture, we learned detection (IQR, Z-score), options for handling (remove/winsorize), and sensitivity testing. Now, you will adapt those methods to a provided dataset and document the risks and assumptions behind your choices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "np.random.seed(17)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data (provided or synthetic fallback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = Path('data/raw/outliers_homework.csv')\n",
        "if data_path.exists():\n",
        "    df = pd.read_csv(data_path)\n",
        "else:\n",
        "    # Synthetic fallback: linear trend with noise and a few extremes\n",
        "    x = np.linspace(0, 10, 200)\n",
        "    y = 2.2 * x + 1 + np.random.normal(0, 1.2, size=x.size)\n",
        "    y[10] += 15; y[120] -= 13; y[160] += 18\n",
        "    df = pd.DataFrame({'x': x, 'y': y})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TODO: Implement Outlier Functions (required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "grade_required"
        ]
      },
      "outputs": [],
      "source": [
        "def detect_outliers_iqr(series: pd.Series, k: float = 1.5) -> pd.Series:\n",
        "    \"\"\"Return boolean mask for IQR-based outliers.\n",
        "    Assumptions: distribution reasonably summarized by quartiles; k controls strictness.\n",
        "    \"\"\"\n",
        "    q1 = series.quantile(0.25)\n",
        "    q3 = series.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower = q1 - k * iqr\n",
        "    upper = q3 + k * iqr\n",
        "    return (series < lower) | (series > upper)\n",
        "\n",
        "def detect_outliers_zscore(series: pd.Series, threshold: float = 3.0) -> pd.Series:\n",
        "    \"\"\"Return boolean mask for Z-score outliers where |z| > threshold.\n",
        "    Assumptions: roughly normal distribution; sensitive to heavy tails.\n",
        "    \"\"\"\n",
        "    mu = series.mean()\n",
        "    sigma = series.std(ddof=0)\n",
        "    z = (series - mu) / (sigma if sigma != 0 else 1.0)\n",
        "    return z.abs() > threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*(Stretch)* Implement winsorizing (optional)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "stretch"
        ]
      },
      "outputs": [],
      "source": [
        "def winsorize_series(series: pd.Series, lower: float = 0.05, upper: float = 0.95) -> pd.Series:\n",
        "    lo = series.quantile(lower)\n",
        "    hi = series.quantile(upper)\n",
        "    return series.clip(lower=lo, upper=hi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Detection and Create Flags (choose a numeric column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "grade_required"
        ]
      },
      "outputs": [],
      "source": [
        "target_col = 'y' if 'y' in df.columns else df.select_dtypes(include=['number']).columns[0]\n",
        "df['outlier_iqr'] = detect_outliers_iqr(df[target_col])\n",
        "df['outlier_z'] = detect_outliers_zscore(df[target_col], threshold=3.0)\n",
        "df[['outlier_iqr', 'outlier_z']].mean()  # fraction flagged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visual Checks (boxplot / histogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.boxplot(df[target_col])\n",
        "plt.title(f'Boxplot: {target_col}')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(df[target_col], bins=30)\n",
        "plt.title(f'Histogram: {target_col}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sensitivity Analysis\n",
        "Pick one: summary stats or simple linear regression comparing **all vs. filtered** (and optional winsorized)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "grade_required"
        ]
      },
      "outputs": [],
      "source": [
        "# Option A: Summary stats\n",
        "summ_all = df[target_col].describe()[['mean', '50%', 'std']].rename({'50%': 'median'})\n",
        "summ_filtered = df.loc[~df['outlier_iqr'], target_col].describe()[['mean', '50%', 'std']].rename({'50%': 'median'})\n",
        "summ_w = None\n",
        "if 'winsorize_series' in globals():\n",
        "    w = winsorize_series(df[target_col])\n",
        "    summ_w = w.describe()[['mean', '50%', 'std']].rename({'50%': 'median'})\n",
        "\n",
        "comp = pd.concat(\n",
        "    {\n",
        "        'all': summ_all,\n",
        "        'filtered_iqr': summ_filtered,\n",
        "        **({'winsorized': summ_w} if summ_w is not None else {})\n",
        "    }, axis=1\n",
        ")\n",
        "comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "grade_required"
        ]
      },
      "outputs": [],
      "source": [
        "# Option B: Simple regression (if x present)\n",
        "if 'x' in df.columns:\n",
        "    X_all = df[['x']].to_numpy(); y_all = df[target_col].to_numpy()\n",
        "    X_filtered = df.loc[~df['outlier_iqr'], ['x']].to_numpy(); y_filtered = df.loc[~df['outlier_iqr'], target_col].to_numpy()\n",
        "\n",
        "    model_all = LinearRegression().fit(X_all, y_all)\n",
        "    model_flt = LinearRegression().fit(X_filtered, y_filtered)\n",
        "\n",
        "    mae_all = mean_absolute_error(y_all, model_all.predict(X_all))\n",
        "    mae_flt = mean_absolute_error(y_filtered, model_flt.predict(X_filtered))\n",
        "\n",
        "    results = pd.DataFrame({\n",
        "        'slope': [model_all.coef_[0], model_flt.coef_[0]],\n",
        "        'intercept': [model_all.intercept_, model_flt.intercept_],\n",
        "        'r2': [model_all.score(X_all, y_all), model_flt.score(X_filtered, y_filtered)],\n",
        "        'mae': [mae_all, mae_flt]\n",
        "    }, index=['all', 'filtered_iqr'])\n",
        "    results\n",
        "else:\n",
        "    results = None\n",
        "    print(\"No 'x' column; skip regression or engineer features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection (≤ 1 page)\n",
        "- Methods and thresholds used (and why)\n",
        "- Assumptions behind choices\n",
        "- Observed impact on results\n",
        "- Risks if assumptions are wrong (e.g., discarding true events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Write your reflection here...*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
